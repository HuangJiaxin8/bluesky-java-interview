import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as d,c,b as l,d as i,e,f as t}from"./app-a0ba2b3f.js";const u={},k=t('<h1 id="mq" tabindex="-1"><a class="header-anchor" href="#mq" aria-hidden="true">#</a> MQ</h1><h2 id="mq-1" tabindex="-1"><a class="header-anchor" href="#mq-1" aria-hidden="true">#</a> MQ</h2><ul><li><p>MQ 有哪几种工作模式</p><ul><li>点对点模式（一对一）</li><li>发布订阅（一对多）</li></ul></li><li><p>为什么使用消息队列</p><ul><li>解耦、异步、削峰</li><li>解耦 <ul><li>A系统发送数据到BCD三个系统，通过接口调用发送。</li><li>如果E系统也要这个接口呢？如果D系统现在又不需要了呢？这时候A系统的负责人就会很崩溃。</li><li>引入了MQ之后，A系统只需要产生一个数据，发送到MQ里面去，哪个系统需要就去MQ消费。</li></ul></li><li>异步 <ul><li>A系统接收一个任务，需要自己写在本库，还要写BCD三个库。写完之后再响应客户，这样是比较耗时的。</li><li>引入MQ之后，A系统只需要写在本库，然后把数据发送到MQ里面，就可以响应用户了。BCD在后台读取MQ的数据，然后写库。</li></ul></li><li>削峰： <ul><li>减少高峰期对服务器的压力。</li></ul></li></ul></li><li><p>MQ有什么优缺点</p><ul><li>优点：解耦、异步、削峰</li><li>缺点： <ul><li>系统可用性降低，引入MQ组件，万一MQ组件挂了怎么办呢</li><li>系统复杂性提高，多了个MQ组件，MQ组件产生的问题也要解决。比如，怎么保证消息没有重复消费？消息丢失怎么办？如何保证消息传递的顺序性？</li><li>一致性问题：A系统写完数据，人都以为这个请求成功了。然后后台BCD三个系统，万一D写库失败了怎么办？这会导致数据不一致的问题。</li></ul></li></ul></li><li><p>说一下生产者，消费者模式</p><ul><li>所谓生产者-消费者问题，实际上主要是包含了两类线程。一种是生产者线程用于生产数据，另一种是消费者线程用于消费数据，为了解耦生产者和消费者的关系，通常会采用共享的数据区域，就像是一个仓库。</li><li>生产者生产数据之后直接放置在共享数据区中，并不需要关心消费者的行为。而消费者只需要从共享数据区中去获取数据，就不再需要关心生产者的行为。</li><li>但是，这个共享数据区域中应该具备这样的线程间并发协作的功能： <ul><li>使用 Object 的 wait/notify 的消息通知机制；</li><li>使用 Lock 的 Condition 的 await/signal 的消息通知机制；</li><li>使用 BlockingQueue 实现。</li></ul></li></ul></li></ul><p>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</p><table><thead><tr><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>开发语言</td><td>java</td><td>erlang</td><td>java</td><td>scala</td></tr><tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>万级</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr><tr><td>topic 数量对吞吐量的影响</td><td></td><td></td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td>基本不丢</td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr><tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr><tr><td>社区活跃度</td><td>低</td><td>很高</td><td>一般</td><td>很高</td></tr></tbody></table><figure><img src="https://secure2.wostatic.cn/static/kcAr2p9i7p2VyiMz89Ssva/image.png?auth_key=1691510098-h14rM9wLqAaANeKn58gVCd-0-298776efdf20a2e63bd004b4df495469" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>什么是mq的重试机制 <ul><li>消费者消费失败后，那么mq会对消息进行重发，达到一定的阈值后，把消息放到死信队列里，然后不再重试</li></ul></li><li>什么是死信队列 <ul><li>消费者消费失败后，mq重发次数达到阈值，会把消息放到死信队列里</li></ul></li><li>什么是延迟队列 <ul><li>顾名思义，就是延迟一段时间后再发送消息给消费者</li></ul></li></ul><h2 id="kafka" tabindex="-1"><a class="header-anchor" href="#kafka" aria-hidden="true">#</a> Kafka</h2><ul><li>什么是kafka <ul><li>Apach Kafka是一款分布式流处理平台</li><li>常作为企业级的消息引擎</li></ul></li><li>kafka是怎么设计的 <ul><li>kafka将消息以topic为单位进行归档</li><li>kafka以集群的方式运行，一般以多个服务运行，每个服务叫做broker，一般也叫做节点</li><li>向kafka集群发布topic消息的程序称为producer</li><li>向kafka订阅topic消息并消费的程序称为consumer</li><li>topic被分为多个partition，每个partition被分布在不同的broker上，每个 partition 只存放一部分数据</li></ul></li><li>kafka如何保证高可用性 <ul><li>kafka的基本架构组成： <ul><li>由多个broker组成的一个集群，每个broker一般我们称之为一个节点</li><li>当创建一个topic时，每一个topic都会被分为多个partition，每个partition只存一部分数据，每个partition被分布在不同的broker上</li></ul></li><li>这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。</li><li>在kafka0.8版本以前，是没有HA（高可用）机制，当任何一个broker节点宕机了，这个broker上的partition就无法提供服务。所以这个版本没有高可用。</li><li>在kafka0.8版本以后，提供了HA机制，也就是说每个partition都提供了副本replica，这些副本分布在不同的broker上，也就是说一个broker宕机，也不会影响总体使用。 <ul><li>所有的replica会选举出一个leader，生产者和消费者都会跟这个leader节点进行通信，其他replica会作为follower。</li><li>写数据的时候，生产者只将数据写入 <code>leader</code> 节点，<code>leader</code> 会将数据写入本地磁盘，接着其他 <code>follower</code> 会主动从 <code>leader</code> 来拉取数据，<code>follower</code> 同步好数据了，就会发送 <code>ack</code> 给 <code>leader</code>，<code>leader</code> 收到所有 <code>follower</code> 的 <code>ack</code> 之后，就会返回写成功的消息给生产者。</li><li>消费数据的时候，消费者只会从 <code>leader</code> 节点去读取消息</li></ul></li></ul></li></ul>',9),f={href:"https://www.javalearn.cn/#/doc/MQ/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98?id=_4-kafka-%E6%B6%88%E6%81%AF%E6%98%AF%E9%87%87%E7%94%A8-pull-%E6%A8%A1%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%98%AF-push-%E6%A8%A1%E5%BC%8F%EF%BC%9F",target:"_blank",rel:"noopener noreferrer"},p=t("<ul><li>推拉模式指的是 Comsumer 和 Broker 之间的交互。</li><li>推模式 <ul><li>推模式指的是消息从 Broker 推向 Consumer</li><li>好处： <ul><li>实时性高</li><li>对于消费者使用来说更简单</li></ul></li><li>坏处： <ul><li>推送速率难以适应消费速率，适用于消息量不大、消费能力强要求实时性高的情况下</li></ul></li></ul></li><li>拉模式 <ul><li>拉模式指的是 Consumer 主动向 Broker 请求拉取消息 <ul><li>好处： <ul><li>消费者可以根据自身的情况来发起拉取消息的请求</li></ul></li><li>坏处： <ul><li>消息延迟</li></ul></li></ul></li></ul></li><li>个人觉得拉模式更加的合适，因为现在的消息队列都有持久化消息的需求，也就是说本身它就有个存储功能，它的使命就是接受消息，保存好消息使得消费者可以消费消息即可。</li></ul>",1),n={href:"https://www.javalearn.cn/#/doc/MQ/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98?id=_5-kafka-%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB",target:"_blank",rel:"noopener noreferrer"},s={href:"https://www.javalearn.cn/#/doc/MQ/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98?id=_6-%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%EF%BC%9F",target:"_blank",rel:"noopener noreferrer"},h=t('<ul><li><p>Kafka中，ZooKeeper的作用</p><ul><li>Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。 <ul><li>“存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。</li><li>“成员管理” 是指 Broker 节点的注册、注销以及属性变更等</li><li>“Controller 选举” 是指选举集群 Controller</li><li>其他管理类任务包括主题删除、参数配置等。</li></ul></li></ul></li><li><p>Kafka中位移/偏移量（offset）的作用</p><ul><li>每个主题分区下的每条消息都被赋予了一个唯一的ID数值，用于标识它在分区中的位置，这个id就叫offset</li><li>一旦消息被写入到分区日志，它的位移值将不能被修改。</li></ul></li><li><p>重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。</p></li><li><p>kafka为什么快</p><ul><li>Cache Filesystem Cache PageCache缓存</li><li>顺序写：由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。</li><li>Zero-copy：零拷技术减少拷贝次数</li><li>Batching of Messages/批量量处理:合并小的请求，然后以流的方式进行交互</li><li>Pull 拉模式：使用拉模式进行消息的消费</li></ul></li><li><p>kafka如何实现高性能IO</p><ul><li>按批发送：kafka没有提供单条消息发送的功能，每次发送消息都会存到客户端内存，消息积累到一定程度才会按批次发送给broker。减少了IO次数。</li><li>磁盘顺序写：磁盘顺序读写是要比随机读写性能高几倍到几十倍。kafka利用磁盘顺序写的特性提高性能。对于每个分区，它把从生产者收到的消息都顺序写入到log文件中，消费的时候也是从某个全局的位置中顺序的读出来。</li><li>利用PageCache加速消息读写，所谓的pageCache就是现代操作系统提供的一个功能，现代操作系统会在内存中开辟一块内存给磁盘最为缓存。读写都会经过这块缓存，缓存的意义都是提高效率。 <ul><li>读有两张情况： <ul><li>一种是PageChache有数据，那么就正常的读取来</li><li>另外一种是PageCache没有数据，那么就发生缺页中断，应用读取线程会阻塞，操作系统读磁盘数据到PageCache，然后应用线程再去PageCache读取。</li></ul></li></ul></li><li>零拷贝：零拷贝是操作系统提供的特性，可以提高消费的性能。 <ul><li>正常情况我们处理消费的逻辑大致是这样： <ul><li>首先从文件找到消息，读取到PageCache中。</li><li>然后应用读取PageCache然后再通过网络发送到客户端。</li></ul></li><li>上面这个过程做了2-3次拷贝。分别是文件到PageCache（如果PageCache命中就减少这一次），PageCache到应用，应用到socket缓存区。</li><li>而有了零拷贝技术，那么可以直接由PageCache读取数据到socket缓冲区，减少一次数据的复制，当然，更重要的是可以减少操作系统内核态和用户态的切换（这个能节省大量的时间）。</li></ul></li></ul></li><li><p>Kafka中的ISR、AR代表什么？ISR的伸缩指什么？</p><ul><li><code>ISR</code>：In-Sync Replicas 副本同步队列</li><li><code>AR</code>:Assigned Replicas 所有副本</li><li>OSR（Outof-Sync Replicas）</li><li>AR=ISR+OSR。</li><li>ISR的伸缩 <ul><li>ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度，当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度）</li><li>任意一个超过阈值都会把follower剔除出ISR，存入OSR列表，新加入的follower也会先存放在OSR中。</li></ul></li></ul></li><li><p>kafka producer发送数据，ack为0，1，-1分别是什么意思？</p><ul><li>1：（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。 <ul><li>在这种情况下，如果leader宕机了，则会丢失数据。</li></ul></li><li>0 ：生产者将数据发送出去就不管了，不去等待任何返回。 <ul><li>这种情况下数据传输效率最高，但是数据可靠性确是最低的</li></ul></li><li>-1： producer需要等待ISR中的所有follower都确认接收到数据后才算发送完成，可靠性最高。</li></ul></li><li><p>为什么Kafka不支持读写分离？</p><ul><li>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。</li><li>Kafka 并不支持主写从读 <ul><li>数据一致性问题。</li><li>延时问题。 <ul><li>类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。</li><li>而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</li></ul></li></ul></li></ul></li><li><p>描述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别</p><ul><li>kafka副本当前分为Leader副本和Follower副本。 <ul><li>只有Leader副本才能对外提供读写服务，响应Clients端的请求。</li><li>Follower副本只是采用拉（PULL）的方式，同步Leader副本中的数据</li><li>在Leader副本所在的Broker宕机后，随时准备应聘Leader副本。</li></ul></li></ul></li><li><p>kafka如何保证消息不丢失</p><ul><li>生产者，kafka，消费者都可能丢失数据</li><li>消费者异常导致的消息丢失 <ul><li>消费者获取了消息，提交了offset，消息还没处理发生了宕机，kafka却认为消息处理完了。</li><li>解决方案：关闭自动提交offset，改为手动offset。 <ul><li>手动offset带来的问题：会有重复消费问题，消费者处理完了，然后提交了offset，然后宕机了，此时这条消息可能会被重复消费一次。</li><li>解决：客户端根据实际情况来保证幂等性问题</li></ul></li></ul></li><li>生产者异常导致的消息丢失 <ul><li>生产者发送消息给 Kafka，由于网络等原因导致消息丢失</li><li>解决方案 <ul><li>通过在 producer 端设置 acks=all 来处理，这个参数是要求 leader 接收到消息后，需要等到所有的 follower 都同步到了消息之后，才认为本次写成功了。</li><li>如果没满足这个条件，生产者会自动不断的重试。</li></ul></li></ul></li><li>kafka异常丢失数据 <ul><li>Kafka 导致的数据丢失一个常见的场景就是 Kafka 某个 broker 宕机，而这个节点正好是某个 partition 的 leader 节点，这时需要重新重新选举该 partition 的 leader。</li><li>如果该 partition 的 leader 在宕机时刚好还有些数据没有同步到 follower，此时 leader 挂了，在选举某个 follower 成 leader 之后，就会丢失一部分数据。</li><li>对于这个问题，Kafka 可以设置如下 4 个参数，来尽量避免消息丢失： <ul><li>给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本；</li><li>Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个参数的含义是一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 节点。</li><li>在 producer 端设置 acks=all，这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了；</li><li>在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了。</li></ul></li></ul></li></ul></li><li><p>Kafka 如何保证消息的顺序性</p><ul><li>对于如何保证消息的顺序性，主要需要考虑如下两点：</li><li>如何保证消息在 Kafka 中顺序性： <ul><li>对于 Kafka，如果我们创建了一个 topic，默认会分为三个 partition。</li><li>生产者在写数据的时候，可以指定一个 key，比如在订单 topic 中我们可以指定订单 id 作为 key，那么相同订单 id 的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的</li><li>也就是说，通过指定 <code>key</code> 的方式，可以保证在 <code>kafka</code> 内部，消息是有序的。</li></ul></li><li>如何保证消费者处理消费的顺序性 <ul><li>如果消费者是单线程处理，只要保证partition在kafka的顺序性就行了</li><li>如果消费者是多线程的话，key相同的话，就放到同一个内存队列去。每个线程去内存队列获取就行了。</li></ul></li></ul></li><li><p>Kafka是CAP理论中的CP还是AP呢</p><ul><li>kakfa可以通过配置修改成CP系统或者AP系统</li></ul></li><li><p>Kafka没有实现延时队列、死信队列、也没有重试机制。但是Spring-Kafka 封装了消费重试和死信队列。</p></li><li><p>Kafka 如何实现延时队列</p><ul><li>首先，先讲一个常见的业务场景吧，我们对这个场景进行扩展。比如，一个订单场景，一个用户下单后，如果超过30分钟后还没付款，那么我们就要取消这个订单，这时候就可以用延时队列了。</li><li>方案一： <ul><li>订单服务，用户下单就会生成一个新订单，然后把订单发送给kafka，因为kafka不支持延时队列，所以，我们自己做一个延迟服务，把kafka的订单消息发送给延时服务。</li><li>这个延时服务，过了30分钟后就要把这个订单消息发送kafka，然后订单服务消费这个延迟消息，再做业务处理（判断用户是否付款，如果没有付款就取消订单）。</li><li>至于这个延时服务，我们可以用Java的延时队列来做。</li><li>需要注意的是，我们需要保证延时服务的相对的可靠性，需要做： <ul><li>延迟消息的消费者手动提交offset</li><li>延迟消息的消费者要做幂等性处理（根据业务需要）</li><li>延时服务做 集群</li></ul></li><li><strong>问题</strong>：如果延时服务挂了，那么将会丢掉消息，即使做集群，也会丢失。比如，消息A发送给节点A，节点A挂了，消息A的数据就丢了。后续流量都打到节点B，也就是集群只是保证后续消息的可靠性。</li><li>思考：如果一定要用这种方案，如何优化呢？ <ul><li>前端上做文章，比如，前端也搞个计时器，如果超过30分钟，那么订单页面就不要显示。（虽然前端防君子不防小人，但是99.99%的用户都是君子，前端还是有用的）</li><li>人工补偿，运维定时去扫描订单表，如果订单有些因为上诉问题带来未及时关闭的问题，那么运维可以手动关闭。</li></ul></li></ul></li><li>方案二： <ul><li>不要延时服务，订单服务发送一个消息，发送一个消息给kafka，这个消息要添加时间信息：30分钟的时间戳。为了保证顺序性，指定一个key，这样能保证所有消息在同一个partition（同一partition有序）。</li><li>然后订单服务，开启一个线程，一直轮询kafka，如果系统当前时间大于第一个消息的时间戳，那么就可以消费了。</li><li><strong>问题</strong>： <ul><li>带来消息的积压，压力来到kafka这边。</li><li>而且要轮询，消费者也要牺牲一点轮询的性能。</li><li>降低吞吐量，因为指定了key，只使用了一个partition（为了保证消息在kafka内部的有序）。</li></ul></li><li>好处：解决了方案一的问题。</li></ul></li></ul></li></ul><h2 id="rabbitmq" tabindex="-1"><a class="header-anchor" href="#rabbitmq" aria-hidden="true">#</a> RabbitMQ</h2><h2 id="rocketmq" tabindex="-1"><a class="header-anchor" href="#rocketmq" aria-hidden="true">#</a> RocketMQ</h2><ul><li>消息积压如何解决</li></ul>',4);function A(E,B){const a=o("ExternalLinkIcon");return d(),c("div",null,[k,l("p",null,[l("a",f,[i("4. "),e(a)]),i("Kafka之推拉模式")]),p,l("p",null,[l("a",n,[i("5. Kafka 与传统消息系统之间的区别"),e(a)])]),l("p",null,[l("a",s,[i("6. 什么是消费者组？"),e(a)])]),h])}const g=r(u,[["render",A],["__file","mq.html.vue"]]);export{g as default};
